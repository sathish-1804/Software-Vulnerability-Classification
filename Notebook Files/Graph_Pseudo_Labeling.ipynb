{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric transformers faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIAFwVsSeqMu",
        "outputId": "05d8dbcf-55cb-4f4b-812d-6f5e6904d53b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu, torch-geometric\n",
            "Successfully installed faiss-cpu-1.9.0 torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au5QazFiLsio",
        "outputId": "448b8c4d-7fcd-4db6-8c5f-115871593c65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPobuOk4uoBg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/undersampled_data.csv\", low_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GomWIov64ZaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c631cb42-e835-43f8-8e40-dbe738d95047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21800 entries, 0 to 21799\n",
            "Data columns (total 36 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Unnamed: 0                    21800 non-null  int64  \n",
            " 1   Access Gained                 87 non-null     object \n",
            " 2   Attack Origin                 20142 non-null  object \n",
            " 3   Authentication Required       20142 non-null  object \n",
            " 4   Availability                  16668 non-null  object \n",
            " 5   CVE ID                        20221 non-null  object \n",
            " 6   CVE Page                      20142 non-null  object \n",
            " 7   CWE ID                        17610 non-null  object \n",
            " 8   Complexity                    20142 non-null  object \n",
            " 9   Confidentiality               13112 non-null  object \n",
            " 10  Integrity                     12601 non-null  object \n",
            " 11  Known Exploits                0 non-null      float64\n",
            " 12  Publish Date                  20142 non-null  object \n",
            " 13  Score                         20142 non-null  float64\n",
            " 14  Summary                       20142 non-null  object \n",
            " 15  Update Date                   21800 non-null  object \n",
            " 16  Vulnerability Classification  15777 non-null  object \n",
            " 17  add_lines                     21800 non-null  int64  \n",
            " 18  codeLink                      21800 non-null  object \n",
            " 19  commit_id                     21800 non-null  object \n",
            " 20  commit_message                19632 non-null  object \n",
            " 21  del_lines                     21800 non-null  int64  \n",
            " 22  file_name                     19746 non-null  object \n",
            " 23  files_changed                 19746 non-null  object \n",
            " 24  func_after                    21800 non-null  object \n",
            " 25  func_before                   21800 non-null  object \n",
            " 26  lang                          21800 non-null  object \n",
            " 27  lines_after                   9757 non-null   object \n",
            " 28  lines_before                  8243 non-null   object \n",
            " 29  parentID                      2054 non-null   object \n",
            " 30  patch                         21800 non-null  object \n",
            " 31  project                       21800 non-null  object \n",
            " 32  project_after                 21800 non-null  object \n",
            " 33  project_before                21800 non-null  object \n",
            " 34  vul                           21800 non-null  int64  \n",
            " 35  vul_func_with_fix             21800 non-null  object \n",
            "dtypes: float64(2), int64(4), object(30)\n",
            "memory usage: 6.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pvZuh7a5LH7"
      },
      "outputs": [],
      "source": [
        "# Select the relevant columns for the task\n",
        "df_cleaned = data[['func_before', 'func_after', 'lines_before', 'lines_after', 'vul', 'vul_func_with_fix']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W5mqCF38xHO",
        "outputId": "81d0160c-c03d-4a9d-e080-fcdab6c93072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21800 entries, 0 to 21799\n",
            "Data columns (total 6 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   func_before        21800 non-null  object\n",
            " 1   func_after         21800 non-null  object\n",
            " 2   lines_before       8243 non-null   object\n",
            " 3   lines_after        9757 non-null   object\n",
            " 4   vul                21800 non-null  int64 \n",
            " 5   vul_func_with_fix  21800 non-null  object\n",
            "dtypes: int64(1), object(5)\n",
            "memory usage: 1022.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df_cleaned.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waV_oepl82NA",
        "outputId": "85ad8c78-e35e-4153-e12b-25286cc95e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "func_before          0\n",
            "func_after           0\n",
            "lines_before         0\n",
            "lines_after          0\n",
            "vul                  0\n",
            "vul_func_with_fix    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_cleaned.loc[:, 'lines_before'] = df_cleaned['lines_before'].fillna('')\n",
        "df_cleaned.loc[:, 'lines_after'] = df_cleaned['lines_after'].fillna('')\n",
        "\n",
        "# Verify that no missing values remain\n",
        "print(df_cleaned.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "LA-Nn17B_m6C",
        "outputId": "1bd1966c-2602-4c6b-f126-989112251867"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vul\n",
              "0    10900\n",
              "1    10900\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vul</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_cleaned['vul'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjbMPNEHAR09",
        "outputId": "3f0ab0b4-27b3-470b-f523-485285fa9e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vul\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n",
            "vul\n",
            "1    0.5\n",
            "0    0.5\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into 10% train and 90% test set\n",
        "train_df, test_df = train_test_split(df_cleaned, test_size=0.9, stratify=df_cleaned['vul'], random_state=42)\n",
        "\n",
        "# Check the distribution of vulnerability labels\n",
        "print(train_df['vul'].value_counts(normalize=True))\n",
        "print(test_df['vul'].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH8SUO32DUod",
        "outputId": "57f7a14f-e445-4624-810c-bc84b9237d47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2180, 19620)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(train_df), len(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CodeBert for embeddings for sample dataset"
      ],
      "metadata": {
        "id": "kywPn4aoC691"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "# Set the GPU device (if available) in Google Colab\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load a smaller pre-trained tokenizer and model (DistilBERT instead of CodeBERT)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "\n",
        "# Function to tokenize and vectorize code snippets using DistilBERT, with batch processing\n",
        "def code_to_embeddings(code_snippets, batch_size=100):\n",
        "    all_embeddings = []\n",
        "\n",
        "    # Process data in batches to avoid memory overload\n",
        "    for i in range(0, len(code_snippets), batch_size):\n",
        "        batch = code_snippets[i:i + batch_size]\n",
        "\n",
        "        # Tokenize the code snippets and obtain the input IDs\n",
        "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Move the inputs to the same GPU device\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "        # Get the embeddings from the DistilBERT model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the last hidden state as the vector representation of the code (mean pooling)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)  # (batch_size, hidden_size)\n",
        "        all_embeddings.append(embeddings.cpu())  # Move the embeddings to CPU to free up GPU memory\n",
        "\n",
        "    # Concatenate all batches to get the full embeddings\n",
        "    return torch.cat(all_embeddings, dim=0)\n",
        "\n",
        "# --- Generate embeddings for all relevant columns on the new sample subset (5,000 records) ---\n",
        "\n",
        "# Tokenize and generate embeddings for each column separately\n",
        "X_train_func_before = code_to_embeddings(list(train_df['func_before']))\n",
        "X_test_func_before = code_to_embeddings(list(test_df['func_before']))\n",
        "\n",
        "X_train_func_after = code_to_embeddings(list(train_df['func_after']))\n",
        "X_test_func_after = code_to_embeddings(list(test_df['func_after']))\n",
        "\n",
        "X_train_lines_before = code_to_embeddings(list(train_df['lines_before']))\n",
        "X_test_lines_before = code_to_embeddings(list(test_df['lines_before']))\n",
        "\n",
        "X_train_lines_after = code_to_embeddings(list(train_df['lines_after']))\n",
        "X_test_lines_after = code_to_embeddings(list(test_df['lines_after']))\n",
        "\n",
        "X_train_vul_fix = code_to_embeddings(list(train_df['vul_func_with_fix']))\n",
        "X_test_vul_fix = code_to_embeddings(list(test_df['vul_func_with_fix']))\n",
        "\n",
        "# Combine embeddings for training and test data (concatenation along dim=1)\n",
        "X_train_embeddings = torch.cat((X_train_func_before, X_train_func_after, X_train_lines_before, X_train_lines_after, X_train_vul_fix), dim=1)\n",
        "X_test_embeddings = torch.cat((X_test_func_before, X_test_func_after, X_test_lines_before, X_test_lines_after, X_test_vul_fix), dim=1)\n",
        "\n",
        "# Labels (these remain the same)\n",
        "y_train = train_df['vul'].values\n",
        "y_test = test_df['vul'].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwr7HTn5DDhh",
        "outputId": "5b5589b1-2cb6-4c97-bd9c-9ca55f61157b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training and test embeddings as PyTorch tensors\n",
        "torch.save(X_train_embeddings, '/content/drive/MyDrive/X_train_embeddings.pt')\n",
        "torch.save(X_test_embeddings, '/content/drive/MyDrive/X_test_embeddings.pt')\n",
        "\n",
        "# If you also want to save the labels\n",
        "torch.save(torch.tensor(y_train), '/content/drive/MyDrive/y_train.pt')\n",
        "torch.save(torch.tensor(y_test), '/content/drive/MyDrive/y_test.pt')\n",
        "\n",
        "print(\"Embeddings and labels saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h18KgM3ZDuRc",
        "outputId": "0a1a4a5e-901c-46dc-8c12-6a1a9d771b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings and labels saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph creation\n"
      ],
      "metadata": {
        "id": "bNpgCWM_ruht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Import Necessary Libraries ----\n",
        "\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# ---- Set Device ----\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---- Load Saved Embeddings and Labels ----\n",
        "\n",
        "# Load embeddings from saved files and move to CPU for FAISS processing\n",
        "X_train_embeddings = torch.load('/content/drive/MyDrive/X_train_embeddings.pt').cpu().numpy()\n",
        "X_test_embeddings = torch.load('/content/drive/MyDrive/X_test_embeddings.pt').cpu().numpy()\n",
        "\n",
        "# Load labels from saved files\n",
        "y_train = torch.load('/content/drive/MyDrive/y_train.pt')\n",
        "y_test = torch.load('/content/drive/MyDrive/y_test.pt')\n",
        "\n",
        "# ---- Combine Embeddings ----\n",
        "\n",
        "# Concatenate train and test embeddings\n",
        "all_embeddings = np.concatenate([X_train_embeddings, X_test_embeddings], axis=0)\n",
        "\n",
        "# ---- Dimensionality Reduction using PCA ----\n",
        "\n",
        "# Reduce dimensionality to manage resource constraints\n",
        "pca_components = 256  # Adjust this number based on your resource availability\n",
        "pca = PCA(n_components=pca_components)\n",
        "\n",
        "# Fit PCA on all embeddings and transform\n",
        "all_embeddings_reduced = pca.fit_transform(all_embeddings)\n",
        "\n",
        "\n",
        "# Make sure the array is C-contiguous\n",
        "all_embeddings_reduced = np.ascontiguousarray(all_embeddings_reduced)\n",
        "\n",
        "# ---- Normalize Embeddings for Cosine Similarity ----\n",
        "\n",
        "# Normalize embeddings to unit length for cosine similarity\n",
        "faiss.normalize_L2(all_embeddings_reduced)\n",
        "\n",
        "# ---- Initialize FAISS Index ----\n",
        "\n",
        "# Use IndexFlatIP for inner product (cosine similarity)\n",
        "index = faiss.IndexFlatIP(pca_components)\n",
        "\n",
        "# Add embeddings to the index\n",
        "index.add(all_embeddings_reduced)\n",
        "\n",
        "# ---- Perform KNN Search ----\n",
        "\n",
        "K = 20  # Number of nearest neighbors\n",
        "distances, indices = index.search(all_embeddings_reduced, K)\n",
        "\n",
        "# ---- Construct KNN Graph ----\n",
        "\n",
        "# Create an undirected graph\n",
        "graph = nx.Graph()\n",
        "\n",
        "# Add edges to the graph\n",
        "num_nodes = all_embeddings_reduced.shape[0]\n",
        "\n",
        "for i in range(num_nodes):\n",
        "    for j in indices[i]:\n",
        "        if i != j:  # Avoid self-loops\n",
        "            graph.add_edge(i, j)\n",
        "\n",
        "# ---- Convert NetworkX Graph to PyTorch Geometric Data ----\n",
        "\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# Convert the NetworkX graph into a PyTorch Geometric data object\n",
        "data = from_networkx(graph)\n",
        "\n",
        "# Add node features (embeddings) to the data\n",
        "data.x = torch.tensor(all_embeddings_reduced, dtype=torch.float)\n",
        "\n",
        "# ---- Prepare Labels ----\n",
        "\n",
        "# For test nodes, use -1 as placeholder for unlabeled data\n",
        "y_test_unlabeled = torch.full((len(y_test),), -1, dtype=torch.long)\n",
        "\n",
        "# Concatenate labels\n",
        "labels = torch.cat([y_train, y_test_unlabeled], dim=0)\n",
        "\n",
        "# Add labels to the data\n",
        "data.y = labels\n",
        "\n",
        "# ---- Move Data to Device ----\n",
        "\n",
        "# Move data to the appropriate device\n",
        "data = data.to(device)\n",
        "\n",
        "print(\"Graph reconstruction complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrR03G91ruLB",
        "outputId": "65b1253d-a06a-48e4-8871-192d4761f063"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8285d7018c73>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_train_embeddings = torch.load('/content/drive/MyDrive/X_train_embeddings.pt').cpu().numpy()\n",
            "<ipython-input-3-8285d7018c73>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_test_embeddings = torch.load('/content/drive/MyDrive/X_test_embeddings.pt').cpu().numpy()\n",
            "<ipython-input-3-8285d7018c73>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_train = torch.load('/content/drive/MyDrive/y_train.pt')\n",
            "<ipython-input-3-8285d7018c73>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_test = torch.load('/content/drive/MyDrive/y_test.pt')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph reconstruction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import os\n",
        "\n",
        "# Path where you want to save the processed graph data\n",
        "save_path = '/content/drive/MyDrive/processed_graph_data.pt'\n",
        "\n",
        "# Save the processed graph (data.x for node features and data.y for labels)\n",
        "torch.save({\n",
        "    'x': data.x.cpu(),  # Save the node features\n",
        "    'y': data.y.cpu(),  # Save the labels\n",
        "    'edge_index': data.edge_index.cpu()  # Save the graph edge indices\n",
        "}, save_path)\n",
        "\n",
        "print(f\"Graph and node features saved to {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns2wpYILA_Oe",
        "outputId": "4a672ee1-5da1-4caf-cb13-97d8061e7361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph and node features saved to /content/drive/MyDrive/processed_graph_data.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "wL5g0HaqrzjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Import Necessary Libraries ----\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# ---- Set Device ----\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---- Define the Simplified GCN Model ----\n",
        "\n",
        "class SimpleGCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.4):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x  # Raw logits\n",
        "\n",
        "# ---- Define Accuracy Function ----\n",
        "\n",
        "def accuracy(pred, labels):\n",
        "    preds = pred.argmax(dim=1)\n",
        "    correct = preds.eq(labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "# ---- Early Stopping Mechanism ----\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "\n",
        "    def __call__(self, counter):\n",
        "        return counter >= self.patience\n",
        "\n",
        "# ---- Prepare Data and Move to Device ----\n",
        "\n",
        "# Assume 'data' is your PyTorch Geometric data object\n",
        "# Ensure 'data' contains 'x', 'edge_index', and 'y'\n",
        "data = data.to(device)\n",
        "data.y = data.y.long()\n",
        "\n",
        "# ---- Initialize Model, Optimizer, and Loss Function ----\n",
        "\n",
        "input_dim = data.x.shape[1]  # Should be 256 after PCA\n",
        "hidden_dim = 128  # Adjust based on resources\n",
        "output_dim = 2  # Binary classification\n",
        "\n",
        "model = SimpleGCN(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, dropout=0.4).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "# ---- Create Training and Validation Masks ----\n",
        "\n",
        "# Get indices of labeled nodes\n",
        "labeled_idx = (data.y != -1).nonzero(as_tuple=True)[0]\n",
        "\n",
        "# Split indices into training and validation sets\n",
        "train_idx, val_idx = train_test_split(\n",
        "    labeled_idx.cpu(),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=data.y[labeled_idx].cpu()\n",
        ")\n",
        "\n",
        "# Create boolean masks on the correct device\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
        "train_mask[train_idx] = True\n",
        "\n",
        "val_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
        "val_mask[val_idx] = True\n",
        "\n",
        "# ---- Compute Class Weights ----\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(data.y[train_mask].cpu()),\n",
        "    y=data.y[train_mask].cpu().numpy()\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# ---- Define the Training Function ----\n",
        "\n",
        "def train_model(data, model, optimizer, loss_fn, epochs=50, patience=10):\n",
        "    early_stopping = EarlyStopping(patience=patience)\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = loss_fn(out[train_mask], data.y[train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_out = model(data)\n",
        "            val_loss = loss_fn(val_out[val_mask], data.y[val_mask])\n",
        "            val_acc = accuracy(val_out[val_mask], data.y[val_mask])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "              f\"Train Loss: {loss.item():.4f}, \"\n",
        "              f\"Val Loss: {val_loss.item():.4f}, \"\n",
        "              f\"Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Check for improvement\n",
        "        if val_loss.item() < best_val_loss - early_stopping.delta:\n",
        "            best_val_loss = val_loss.item()\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            early_stopping.counter = 0\n",
        "        else:\n",
        "            early_stopping.counter += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if early_stopping(early_stopping.counter):\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "# ---- Train the Model ----\n",
        "\n",
        "train_model(data, model, optimizer, loss_fn, epochs=50, patience=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkpBJJHDr4Oc",
        "outputId": "5ac39410-0b9f-4e0a-c423-5b4224e96ac8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 0.6937, Val Loss: 0.6914, Val Acc: 0.5000\n",
            "Epoch 2/50, Train Loss: 0.6912, Val Loss: 0.6895, Val Acc: 0.5138\n",
            "Epoch 3/50, Train Loss: 0.6888, Val Loss: 0.6877, Val Acc: 0.5298\n",
            "Epoch 4/50, Train Loss: 0.6869, Val Loss: 0.6860, Val Acc: 0.5872\n",
            "Epoch 5/50, Train Loss: 0.6847, Val Loss: 0.6844, Val Acc: 0.6468\n",
            "Epoch 6/50, Train Loss: 0.6828, Val Loss: 0.6830, Val Acc: 0.6766\n",
            "Epoch 7/50, Train Loss: 0.6811, Val Loss: 0.6817, Val Acc: 0.6606\n",
            "Epoch 8/50, Train Loss: 0.6794, Val Loss: 0.6803, Val Acc: 0.6583\n",
            "Epoch 9/50, Train Loss: 0.6777, Val Loss: 0.6788, Val Acc: 0.6537\n",
            "Epoch 10/50, Train Loss: 0.6759, Val Loss: 0.6772, Val Acc: 0.6812\n",
            "Epoch 11/50, Train Loss: 0.6739, Val Loss: 0.6756, Val Acc: 0.6812\n",
            "Epoch 12/50, Train Loss: 0.6719, Val Loss: 0.6740, Val Acc: 0.6766\n",
            "Epoch 13/50, Train Loss: 0.6701, Val Loss: 0.6724, Val Acc: 0.6743\n",
            "Epoch 14/50, Train Loss: 0.6680, Val Loss: 0.6706, Val Acc: 0.6720\n",
            "Epoch 15/50, Train Loss: 0.6657, Val Loss: 0.6689, Val Acc: 0.6766\n",
            "Epoch 16/50, Train Loss: 0.6640, Val Loss: 0.6672, Val Acc: 0.6651\n",
            "Epoch 17/50, Train Loss: 0.6614, Val Loss: 0.6654, Val Acc: 0.6651\n",
            "Epoch 18/50, Train Loss: 0.6594, Val Loss: 0.6634, Val Acc: 0.6858\n",
            "Epoch 19/50, Train Loss: 0.6563, Val Loss: 0.6615, Val Acc: 0.6766\n",
            "Epoch 20/50, Train Loss: 0.6542, Val Loss: 0.6596, Val Acc: 0.6789\n",
            "Epoch 21/50, Train Loss: 0.6517, Val Loss: 0.6576, Val Acc: 0.6766\n",
            "Epoch 22/50, Train Loss: 0.6492, Val Loss: 0.6557, Val Acc: 0.6789\n",
            "Epoch 23/50, Train Loss: 0.6458, Val Loss: 0.6538, Val Acc: 0.6743\n",
            "Epoch 24/50, Train Loss: 0.6437, Val Loss: 0.6518, Val Acc: 0.6789\n",
            "Epoch 25/50, Train Loss: 0.6413, Val Loss: 0.6498, Val Acc: 0.6812\n",
            "Epoch 26/50, Train Loss: 0.6385, Val Loss: 0.6479, Val Acc: 0.6789\n",
            "Epoch 27/50, Train Loss: 0.6364, Val Loss: 0.6460, Val Acc: 0.6835\n",
            "Epoch 28/50, Train Loss: 0.6339, Val Loss: 0.6442, Val Acc: 0.6766\n",
            "Epoch 29/50, Train Loss: 0.6302, Val Loss: 0.6424, Val Acc: 0.6720\n",
            "Epoch 30/50, Train Loss: 0.6287, Val Loss: 0.6405, Val Acc: 0.6812\n",
            "Epoch 31/50, Train Loss: 0.6249, Val Loss: 0.6388, Val Acc: 0.6835\n",
            "Epoch 32/50, Train Loss: 0.6232, Val Loss: 0.6371, Val Acc: 0.6812\n",
            "Epoch 33/50, Train Loss: 0.6194, Val Loss: 0.6355, Val Acc: 0.6743\n",
            "Epoch 34/50, Train Loss: 0.6183, Val Loss: 0.6339, Val Acc: 0.6743\n",
            "Epoch 35/50, Train Loss: 0.6162, Val Loss: 0.6323, Val Acc: 0.6766\n",
            "Epoch 36/50, Train Loss: 0.6132, Val Loss: 0.6309, Val Acc: 0.6835\n",
            "Epoch 37/50, Train Loss: 0.6113, Val Loss: 0.6296, Val Acc: 0.6743\n",
            "Epoch 38/50, Train Loss: 0.6082, Val Loss: 0.6283, Val Acc: 0.6743\n",
            "Epoch 39/50, Train Loss: 0.6081, Val Loss: 0.6271, Val Acc: 0.6812\n",
            "Epoch 40/50, Train Loss: 0.6049, Val Loss: 0.6260, Val Acc: 0.6697\n",
            "Epoch 41/50, Train Loss: 0.6024, Val Loss: 0.6250, Val Acc: 0.6697\n",
            "Epoch 42/50, Train Loss: 0.6012, Val Loss: 0.6240, Val Acc: 0.6720\n",
            "Epoch 43/50, Train Loss: 0.5978, Val Loss: 0.6232, Val Acc: 0.6743\n",
            "Epoch 44/50, Train Loss: 0.5982, Val Loss: 0.6224, Val Acc: 0.6743\n",
            "Epoch 45/50, Train Loss: 0.5952, Val Loss: 0.6218, Val Acc: 0.6766\n",
            "Epoch 46/50, Train Loss: 0.5948, Val Loss: 0.6212, Val Acc: 0.6697\n",
            "Epoch 47/50, Train Loss: 0.5931, Val Loss: 0.6207, Val Acc: 0.6720\n",
            "Epoch 48/50, Train Loss: 0.5923, Val Loss: 0.6203, Val Acc: 0.6720\n",
            "Epoch 49/50, Train Loss: 0.5908, Val Loss: 0.6199, Val Acc: 0.6697\n",
            "Epoch 50/50, Train Loss: 0.5891, Val Loss: 0.6196, Val Acc: 0.6697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Evaluate the Model on the Validation Set ----\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    val_out = model(data)\n",
        "    val_loss = loss_fn(val_out[val_mask], data.y[val_mask])\n",
        "    val_acc = accuracy(val_out[val_mask], data.y[val_mask])\n",
        "\n",
        "print(f\"Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKocHNuHBQHX",
        "outputId": "3bb3027f-f10f-4669-a621-223c67db91b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6196, Validation Accuracy: 0.6697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-872771b52742>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pth'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pseudo Labelling and Re-Training"
      ],
      "metadata": {
        "id": "FJ8uZKwx1OGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- After Initial Training and Validation Evaluation ----\n",
        "\n",
        "# Apply pseudo-labeling\n",
        "def apply_pseudo_labels(data, model, threshold=0.8):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        out = model(data)  # Forward pass on the entire dataset\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = F.softmax(out, dim=1)\n",
        "    pseudo_labels = torch.argmax(probs, dim=1)\n",
        "\n",
        "    # Ensure data.y is on the correct device before updating\n",
        "    data.y = data.y.to(device)\n",
        "\n",
        "    # Identify high-confidence pseudo-labels for unlabeled nodes (nodes where data.y == -1)\n",
        "    unlabeled_mask = (data.y == -1)\n",
        "    confident_mask = (probs.max(dim=1)[0] > threshold) & unlabeled_mask\n",
        "\n",
        "    # Update the labels for confident predictions\n",
        "    if confident_mask.sum().item() > 0:  # Check if there are any confident nodes\n",
        "        data.y[confident_mask] = pseudo_labels[confident_mask]\n",
        "        print(f\"Pseudo-labeled {confident_mask.sum().item()} nodes.\")\n",
        "    else:\n",
        "        print(\"No confident pseudo-labels were found.\")\n",
        "\n",
        "apply_pseudo_labels(data, model, threshold=0.8)\n",
        "\n",
        "# Update the training mask to include pseudo-labeled nodes\n",
        "pseudo_labeled_mask = (data.y != -1)\n",
        "train_mask = pseudo_labeled_mask.clone()\n",
        "\n",
        "# Recompute class weights with updated labels\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(data.y[train_mask].cpu()),\n",
        "    y=data.y[train_mask].cpu().numpy()\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Re-initialize the model and optimizer\n",
        "model = SimpleGCN(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, dropout=0.4).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "# Retrain the model with the updated training data\n",
        "train_model(data, model, optimizer, loss_fn, epochs=50, patience=10)\n",
        "\n",
        "# Evaluate the retrained model on the validation set\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    val_out = model(data)\n",
        "    val_loss = loss_fn(val_out[val_mask], data.y[val_mask])\n",
        "    val_acc = accuracy(val_out[val_mask], data.y[val_mask])\n",
        "\n",
        "print(f\"Validation Loss after retraining: {val_loss.item():.4f}, Validation Accuracy: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "zzxuwFYb1RBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87958db4-3ae7-4578-8fd3-711b448d1ec9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pseudo-labeled 1710 nodes.\n",
            "Epoch 1/50, Train Loss: 0.6943, Val Loss: 0.6915, Val Acc: 0.5206\n",
            "Epoch 2/50, Train Loss: 0.6873, Val Loss: 0.6898, Val Acc: 0.5252\n",
            "Epoch 3/50, Train Loss: 0.6812, Val Loss: 0.6884, Val Acc: 0.5252\n",
            "Epoch 4/50, Train Loss: 0.6758, Val Loss: 0.6871, Val Acc: 0.5321\n",
            "Epoch 5/50, Train Loss: 0.6708, Val Loss: 0.6857, Val Acc: 0.5505\n",
            "Epoch 6/50, Train Loss: 0.6663, Val Loss: 0.6841, Val Acc: 0.5803\n",
            "Epoch 7/50, Train Loss: 0.6618, Val Loss: 0.6823, Val Acc: 0.6147\n",
            "Epoch 8/50, Train Loss: 0.6569, Val Loss: 0.6806, Val Acc: 0.6583\n",
            "Epoch 9/50, Train Loss: 0.6517, Val Loss: 0.6788, Val Acc: 0.6835\n",
            "Epoch 10/50, Train Loss: 0.6466, Val Loss: 0.6771, Val Acc: 0.6743\n",
            "Epoch 11/50, Train Loss: 0.6410, Val Loss: 0.6754, Val Acc: 0.6651\n",
            "Epoch 12/50, Train Loss: 0.6353, Val Loss: 0.6736, Val Acc: 0.6651\n",
            "Epoch 13/50, Train Loss: 0.6293, Val Loss: 0.6719, Val Acc: 0.6789\n",
            "Epoch 14/50, Train Loss: 0.6231, Val Loss: 0.6702, Val Acc: 0.6904\n",
            "Epoch 15/50, Train Loss: 0.6167, Val Loss: 0.6684, Val Acc: 0.6950\n",
            "Epoch 16/50, Train Loss: 0.6106, Val Loss: 0.6666, Val Acc: 0.6881\n",
            "Epoch 17/50, Train Loss: 0.6036, Val Loss: 0.6645, Val Acc: 0.6927\n",
            "Epoch 18/50, Train Loss: 0.5971, Val Loss: 0.6624, Val Acc: 0.6789\n",
            "Epoch 19/50, Train Loss: 0.5890, Val Loss: 0.6602, Val Acc: 0.6766\n",
            "Epoch 20/50, Train Loss: 0.5825, Val Loss: 0.6580, Val Acc: 0.6674\n",
            "Epoch 21/50, Train Loss: 0.5750, Val Loss: 0.6559, Val Acc: 0.6628\n",
            "Epoch 22/50, Train Loss: 0.5675, Val Loss: 0.6538, Val Acc: 0.6674\n",
            "Epoch 23/50, Train Loss: 0.5597, Val Loss: 0.6517, Val Acc: 0.6674\n",
            "Epoch 24/50, Train Loss: 0.5517, Val Loss: 0.6497, Val Acc: 0.6766\n",
            "Epoch 25/50, Train Loss: 0.5445, Val Loss: 0.6476, Val Acc: 0.6766\n",
            "Epoch 26/50, Train Loss: 0.5379, Val Loss: 0.6454, Val Acc: 0.6789\n",
            "Epoch 27/50, Train Loss: 0.5298, Val Loss: 0.6432, Val Acc: 0.6674\n",
            "Epoch 28/50, Train Loss: 0.5208, Val Loss: 0.6410, Val Acc: 0.6583\n",
            "Epoch 29/50, Train Loss: 0.5138, Val Loss: 0.6390, Val Acc: 0.6560\n",
            "Epoch 30/50, Train Loss: 0.5072, Val Loss: 0.6370, Val Acc: 0.6674\n",
            "Epoch 31/50, Train Loss: 0.4987, Val Loss: 0.6352, Val Acc: 0.6720\n",
            "Epoch 32/50, Train Loss: 0.4926, Val Loss: 0.6334, Val Acc: 0.6743\n",
            "Epoch 33/50, Train Loss: 0.4846, Val Loss: 0.6315, Val Acc: 0.6697\n",
            "Epoch 34/50, Train Loss: 0.4770, Val Loss: 0.6297, Val Acc: 0.6674\n",
            "Epoch 35/50, Train Loss: 0.4714, Val Loss: 0.6280, Val Acc: 0.6628\n",
            "Epoch 36/50, Train Loss: 0.4640, Val Loss: 0.6264, Val Acc: 0.6674\n",
            "Epoch 37/50, Train Loss: 0.4580, Val Loss: 0.6251, Val Acc: 0.6697\n",
            "Epoch 38/50, Train Loss: 0.4506, Val Loss: 0.6237, Val Acc: 0.6766\n",
            "Epoch 39/50, Train Loss: 0.4469, Val Loss: 0.6223, Val Acc: 0.6697\n",
            "Epoch 40/50, Train Loss: 0.4405, Val Loss: 0.6211, Val Acc: 0.6720\n",
            "Epoch 41/50, Train Loss: 0.4350, Val Loss: 0.6200, Val Acc: 0.6720\n",
            "Epoch 42/50, Train Loss: 0.4286, Val Loss: 0.6190, Val Acc: 0.6766\n",
            "Epoch 43/50, Train Loss: 0.4243, Val Loss: 0.6182, Val Acc: 0.6789\n",
            "Epoch 44/50, Train Loss: 0.4194, Val Loss: 0.6174, Val Acc: 0.6835\n",
            "Epoch 45/50, Train Loss: 0.4156, Val Loss: 0.6167, Val Acc: 0.6766\n",
            "Epoch 46/50, Train Loss: 0.4111, Val Loss: 0.6161, Val Acc: 0.6743\n",
            "Epoch 47/50, Train Loss: 0.4074, Val Loss: 0.6156, Val Acc: 0.6812\n",
            "Epoch 48/50, Train Loss: 0.4041, Val Loss: 0.6155, Val Acc: 0.6766\n",
            "Epoch 49/50, Train Loss: 0.4000, Val Loss: 0.6150, Val Acc: 0.6812\n",
            "Epoch 50/50, Train Loss: 0.3966, Val Loss: 0.6147, Val Acc: 0.6720\n",
            "Validation Loss after retraining: 0.6147, Validation Accuracy: 0.6720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-8854f8d80883>:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pth'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "hBsY_Uqv2bqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Define the evaluation function using GPU\n",
        "def evaluate_model(data, n_classes=2):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        out = model(data.to(device))  # Move the data to GPU\n",
        "        pred = out.argmax(dim=1)  # Get the predicted labels\n",
        "        probas = out.softmax(dim=1)  # Get prediction probabilities for ROC-AUC\n",
        "\n",
        "    # Mask for test nodes (unlabeled initially)\n",
        "    test_mask = torch.arange(len(data.y)) >= len(y_train)\n",
        "\n",
        "    # Calculate accuracy on the test set\n",
        "    accuracy = (pred[test_mask] == y_test.to(device)).sum().item() / len(y_test)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Move predictions and true labels back to CPU for sklearn metrics\n",
        "    y_true = y_test.cpu().numpy()\n",
        "    y_pred = pred[test_mask].cpu().numpy()\n",
        "    y_proba = probas[test_mask][:, 1].cpu().numpy()  # Only take the probabilities for the positive class\n",
        "\n",
        "    # Print the confusion matrix\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "    # Print classification report (precision, recall, F1 score)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "    # Compute ROC curve and ROC-AUC for the positive class (class 1)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    roc_auc = roc_auc_score(y_true, y_proba)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC-AUC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "evaluate_model(data, 2)\n"
      ],
      "metadata": {
        "id": "ITd-4f142Llt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "outputId": "3f0d1aed-4d46-483a-b8a5-0526d2f67c9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6804\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6259 3551]\n",
            " [2719 7091]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6971    0.6380    0.6663      9810\n",
            "           1     0.6663    0.7228    0.6934      9810\n",
            "\n",
            "    accuracy                         0.6804     19620\n",
            "   macro avg     0.6817    0.6804    0.6799     19620\n",
            "weighted avg     0.6817    0.6804    0.6799     19620\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X4zgAPtkBlCq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}